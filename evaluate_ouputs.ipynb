{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_types=['war','leader','national_park','monuments']\n",
    "countries=['china','germany','india',\n",
    "           'japan','mexico','russia','spain'\n",
    "          ,'uk','us'\n",
    "           ]\n",
    "languages=['Hindi','English','Spanish','Mandarin','Japanese','Russian','German']\n",
    "model_names=[\n",
    "     'bloomz-7b1',\n",
    "     'Llama-2-7-b-chat-hf',\n",
    "     'Llama-2-13-b-chat-hf',\n",
    "     'Mistral-7B-Instruct',\n",
    "     'Meta-Llama-3-8b-Instruct',\n",
    "     'Aya',\n",
    "     'gpt-4',\n",
    "     'Mixtral-8x7B'\n",
    "     ]\n",
    "def uniform_options(pred):\n",
    "    options=['A ','B ','C ','D ']\n",
    "    pred=pred.replace('(','')\n",
    "    pred=pred.replace(')','')\n",
    "    pred=pred.replace('</s>','')\n",
    "    pred=pred.replace('ãƒ»','')\n",
    "    pred=pred.strip()\n",
    "    if len(pred.split())>0:\n",
    "        if pred[-1]!='.':\n",
    "            pred+='.'\n",
    "    for option in options:\n",
    "        dot_option=option.strip()+'.'+' '\n",
    "        pred=pred.replace(option,dot_option)\n",
    "    return pred\n",
    "\n",
    "def extract_option(pred,options):\n",
    "    options_index=['A.','B.','C.','D.']\n",
    "    for i,option in enumerate(options):\n",
    "        if option in pred:\n",
    "            return options_index[i]\n",
    "    for option in options_index:\n",
    "        if option in pred:\n",
    "            return option\n",
    "    return pred.strip('.')\n",
    "\n",
    "def get_options(prompt):\n",
    "    options=prompt.split('\\n')[-5:-1]\n",
    "    options=[' '.join(i.split()[1:]) for i in options]\n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity_type in entity_types: \n",
    "   # Add outputs in files\n",
    "    for country in countries:\n",
    "        with open(f'data/processed/{entity_type}_qa_{country}.json') as data_file:\n",
    "                data_loaded = json.load(data_file)\n",
    "        for model_name in model_names:\n",
    "            with open(f'data/output/{entity_type}/{country}_{entity_type}_{model_name}.json') as data_file:\n",
    "                data_output = json.load(data_file)\n",
    "            \n",
    "            for data in data_loaded:\n",
    "                id=data['id']\n",
    "                output=data_output[id]\n",
    "                if 'output' in data:\n",
    "                    data['output'][model_name]=output\n",
    "                else:\n",
    "                    data['output']={model_name:output}\n",
    "        with open(f'data/processed/{entity_type}_qa_{country}.json', 'w') as f:\n",
    "            json.dump(data_loaded, f)\n",
    "    #add generatons in files to score\n",
    "    data_to_save=[]\n",
    "    for country in countries:\n",
    "        with open(f'data/processed/{entity_type}_qa_{country}.json') as data_file:\n",
    "                data_loaded = json.load(data_file)\n",
    "        for model_name in model_names:\n",
    "            for data in data_loaded:\n",
    "                id=data['id']\n",
    "                data_answers={}\n",
    "                for lang in languages:\n",
    "                    outputs=data['output'][model_name][lang]\n",
    "                    prompts=data['prompts'][lang][0]\n",
    "                    options=get_options(prompts)\n",
    "                    answers=[]\n",
    "                    for output in outputs:\n",
    "                        output=uniform_options(output)\n",
    "                        output=extract_option(output,options)\n",
    "                        answers.append(output)\n",
    "                    data_answers[lang]=answers\n",
    "                if 'score' in data:\n",
    "                    data['score'][model_name]=data_answers\n",
    "                else:\n",
    "                    data['score']={model_name:data_answers}\n",
    "\n",
    "        with open(f'data/processed/{entity_type}_qa_{country}.json', 'w') as f:\n",
    "            json.dump(data_loaded, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries=['china','germany','india',\n",
    "           'japan','mexico','russia',\n",
    "           'spain','uk','us'\n",
    "           ]\n",
    "languages=['English','German','Spanish','Hindi','Russian',\"Japanese\",'Mandarin']\n",
    "model_names=[\n",
    "     'bloomz-7b1',\n",
    "     'Llama-2-7-b-chat-hf',\n",
    "     'Mistral-7B-Instruct',\n",
    "     'Meta-Llama-3-8b-Instruct',\n",
    "     'Llama-2-13-b-chat-hf',\n",
    "     'Aya',\n",
    "     'gpt-4',\n",
    "     'Mixtral-8x7B'\n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_types=[\n",
    "'monuments',\n",
    "'leader',\n",
    "'war',\n",
    "'national_park'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_dict=['China','India',\n",
    "           'Japan','Mexico','Russia','Spain'\n",
    "          ,'UK','US','Germany'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "data_to_save={\n",
    "     'model':[],\n",
    "     'languages':[],\n",
    "     'score':[],\n",
    "     'country':[],\n",
    "     'id':[],\n",
    "     'entity_type':[]\n",
    "}\n",
    "for entity in entity_types:\n",
    "    for country in countries:\n",
    "        with open(f'data/processed/{entity}_qa_{country}.json') as data_file:\n",
    "                data_loaded = json.load(data_file)\n",
    "        for model_name in model_names:\n",
    "            for data in data_loaded:\n",
    "                for lang in languages:\n",
    "                    outputs=data['score'][model_name][lang]\n",
    "                    true_labels=data['prompt_ans'][lang]\n",
    "                    score=[]\n",
    "                    for output in outputs:\n",
    "                        if output in true_labels:\n",
    "                            score.append(1)\n",
    "                        else:\n",
    "                            score.append(0)\n",
    "                    \n",
    "\n",
    "                    score=sum(score)/len(score)\n",
    "                    data_to_save['model'].append(model_name)\n",
    "                    data_to_save['languages'].append(lang)\n",
    "                    data_to_save['score'].append(score)\n",
    "                    data_to_save['id'].append(data['id'])\n",
    "                    data_to_save['country'].append(country)   \n",
    "                    data_to_save['entity_type'].append(entity)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(data_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity_type in entity_types: \n",
    "    print(entity_type)\n",
    "    radar_plot_values={}\n",
    "    countries_list=['us','china','india','uk','japan','germany', 'russia','mexico', 'spain']\n",
    "    dfe=df[df['entity_type']==entity_type]\n",
    "    for model_name in model_names:\n",
    "        df1=dfe[dfe['model']==model_name]\n",
    "        sd_languages_countries=[]\n",
    "        acc_languages_countries=[]\n",
    "        heat_map_countries=[]\n",
    "        heat_map_languages=[]\n",
    "        for country in countries_list:\n",
    "            heat_map_countries.append(country)\n",
    "            df11=df1[df1['country']==country]\n",
    "            accuracies_language=[]\n",
    "            for lang in languages:\n",
    "                df111=df11[df11['languages']==lang]\n",
    "                accuracies_language.append(sum(df111['score'])/len(df111)*100)\n",
    "            mean = sum(accuracies_language) / len(accuracies_language) \n",
    "            variance = sum([((x - mean) ** 2) for x in accuracies_language]) / len(accuracies_language) \n",
    "            res = variance ** 0.5\n",
    "            sd_languages_countries.append(res)\n",
    "            acc_languages_countries.append(mean)\n",
    "        print(model_name+' &$'+'$&$'.join([str('%.2f'%y)+'+/-'+str('%.2f'%x) for y,x in zip(acc_languages_countries,sd_languages_countries)])\n",
    "              +'$\\\\\\\\')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_iso=['EN','DE','ES','HI','RU','JA','ZH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TC\n",
    "aligned={'bloomz-7b1':{},\n",
    "     'Llama-2-7-b-chat-hf':{},\n",
    "     'Mistral-7B-Instruct':{},\n",
    "     'Meta-Llama-3-8b-Instruct':{},\n",
    "     'Llama-2-13-b-chat-hf':{},\n",
    "     'Aya':{},\n",
    "     'gpt-4':{},\n",
    "     'Mixtral-8x7B':{}}\n",
    "ans={'bloomz-7b1':[],\n",
    "     'Llama-2-7-b-chat-hf':[],\n",
    "     'Mistral-7B-Instruct':[],\n",
    "     'Meta-Llama-3-8b-Instruct':[],\n",
    "     'Llama-2-13-b-chat-hf':[],\n",
    "     'Aya':[],\n",
    "     'gpt-4':[],\n",
    "     'Mixtral-8x7B':[]}\n",
    "U_set=set()\n",
    "\n",
    "for model in model_names:\n",
    "    intersect=U_set\n",
    "    union=set()\n",
    "    m=0\n",
    "    for k,v in aligned[model].items():\n",
    "        m=max(m,len(v))\n",
    "        intersect=intersect.intersection(set(v))\n",
    "        union=union.union(set(v))\n",
    "    score=len(intersect)/len(union)*100\n",
    "    ans[model].append(score)\n",
    "\n",
    "non_hindi=['English','German','Spanish','Russian',\"Japanese\",'Mandarin']\n",
    "\n",
    "for model in model_names:\n",
    "    intersect=U_set\n",
    "    m=0\n",
    "    for l in non_hindi:\n",
    "        v=aligned[model][l]\n",
    "        m=max(m,len(v))\n",
    "        intersect=intersect.intersection(v)\n",
    "        union=union.union(set(v))\n",
    "    score=len(intersect)/len(union)*100\n",
    "    ans[model].append(score)\n",
    "\n",
    "europian=['English','German','Spanish','Russian']\n",
    "\n",
    "for model in model_names:\n",
    "    intersect=U_set\n",
    "    m=0\n",
    "    for l in europian:\n",
    "        v=aligned[model][l]\n",
    "        m=max(m,len(v))\n",
    "        intersect=intersect.intersection(v)\n",
    "        union=union.union(set(v))\n",
    "    score=len(intersect)/len(union)*100\n",
    "    ans[model].append(score)\n",
    "\n",
    "non_europian=['English','Hindi',\"Japanese\",'Mandarin']\n",
    "\n",
    "for model in model_names:\n",
    "    intersect=U_set\n",
    "    m=0\n",
    "    for l in non_europian:\n",
    "        v=aligned[model][l]\n",
    "        m=max(m,len(v))\n",
    "        intersect=intersect.intersection(v)\n",
    "        union=union.union(set(v))\n",
    "    score=len(intersect)/len(union)*100\n",
    "    ans[model].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model,scores in ans.items():\n",
    "    print(model,'&','&'.join([str(\"%.2f\"%x) for x in scores])+'\\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairwise alignment\n",
    "# model_names=['Meta-Llama-3-8b-Instruct']\n",
    "import numpy as np \n",
    "import seaborn as sn \n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    coverage_model=aligned[model_name]\n",
    "    accuracies_languages_countries=[]\n",
    "    heat_map_lang1=[]\n",
    "    heat_map_languages=[]\n",
    "    for lang1 in languages:\n",
    "        heat_map_lang1.append(lang1)\n",
    "        coverage_l1=set(coverage_model[lang1])\n",
    "        accuracies_language=[]\n",
    "        for lang2 in languages:\n",
    "            coverage_l2=coverage_model[lang2]\n",
    "            Tc=len(coverage_l1.intersection(coverage_l2))/len(coverage_l1.union(coverage_l2))\n",
    "            accuracies_language.append(int(Tc*100))\n",
    "        accuracies_languages_countries.append(accuracies_language)\n",
    "    data=np.array(accuracies_languages_countries)\n",
    "    mask = np.triu(np.ones_like(data),k=1) \n",
    "    hm=sn.heatmap(\n",
    "        data=data,\n",
    "        xticklabels=languages_iso,\n",
    "        cmap=\"YlGnBu\",\n",
    "        mask=mask,\n",
    "        annot=True,\n",
    "         fmt='g',\n",
    "        yticklabels=languages_iso)\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.gca().collections[0].set_clim(0,100)\n",
    "    plt.savefig(f'plots/cover_{model_name}.png', bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save={}\n",
    "for i,row in df.iterrows():\n",
    "    lang=row['languages']\n",
    "    mod=row['model']\n",
    "    score=row['score']\n",
    "    if mod in save:\n",
    "        if lang in save[mod]:\n",
    "            save[mod][lang].append(score)\n",
    "        else:\n",
    "            save[mod][lang]=[score]\n",
    "    else:\n",
    "        save[mod]={lang:[score]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m,v in save.items():\n",
    "    for lang,scores in v.items():\n",
    "        v[lang]=sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_models=model_names\n",
    "plot_languages=list(save['bloomz-7b1'].keys())\n",
    "barWidth = 0.10\n",
    "r=np.arange(len(plot_languages))\n",
    "plt.rcParams[\"figure.figsize\"] = (15,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_names=[\n",
    "     'Bloomz-7b1',\n",
    "     'LLaMA-2-7-b-chat',\n",
    "     'Mistral-7B-Instruct',\n",
    "     'Meta-LLaMA-3-8b-Instruct',\n",
    "     'LLaMA-2-13-b-chat',\n",
    "     'Aya',\n",
    "     'GPT-4',\n",
    "     'Mixtral-8x7B'\n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tavle \n",
    "countries_list=['us','china','india','uk','japan','germany', 'russia','mexico', 'spain']\n",
    "for entity_type in entity_types: \n",
    "    print(entity_type)\n",
    "    dfe=df[df['entity_type']==entity_type]\n",
    "    save={}\n",
    "    for i,row in dfe.iterrows():\n",
    "        lang=row['languages']\n",
    "        mod=row['model']\n",
    "        score=row['score']\n",
    "        if mod in save:\n",
    "            if lang in save[mod]:\n",
    "                save[mod][lang].append(score)\n",
    "            else:\n",
    "                save[mod][lang]=[score]\n",
    "        else:\n",
    "            save[mod]={lang:[score]}\n",
    "    for m,v in save.items():\n",
    "        for lang,scores in v.items():\n",
    "            v[lang]=sum(scores)/len(scores)\n",
    "    for i,model in enumerate(plot_models):\n",
    "        Model_name=Model_names[i]\n",
    "        values=list(save[model].values())\n",
    "        values_f=[(i*100) for i in values]\n",
    "        values=[str(\"%.2f\"%(i*100)) for i in values]\n",
    "        avg=sum(values_f)/len(values_f)\n",
    "        avg_w=(values_f[0]+values_f[1]+values_f[2]+values_f[4])/4\n",
    "        values_o='&'.join(values)+'&'+str(\"%.2f\"%avg)+'&'+str(\"%.2f\"%avg_w)+'\\\\\\\\'\n",
    "        print(Model_name+'&'+values_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg={}\n",
    "for model,lang_acc in save.items():\n",
    "    accs=[]\n",
    "    for lang,acc in lang_acc.items():\n",
    "        accs.append(acc)\n",
    "    avg[model]=sum(accs)/len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (9,7)\n",
    "plt.rcParams.update({'font.size': 13})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names_dic={\n",
    "     'bloomz-7b1':'Bloomz-7b1',\n",
    "     'Llama-2-7-b-chat-hf':'Llama-2-7-b-chat',\n",
    "     'Mistral-7B-Instruct':'Mistral-7B-Instruct',\n",
    "     'Meta-Llama-3-8b-Instruct':'Meta-Llama-3-8b-Instruct',\n",
    "     'Llama-2-13-b-chat-hf':'Llama-2-13-b-chat-hf',\n",
    "     'Aya':'Aya',\n",
    "     'gpt-4':'GPT-4',\n",
    "     'Mixtral-8x7B':'Mixtral-8x7B'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_iso=['EN','DE','ES','HI','RU','JA','ZH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle, RegularPolygon\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.projections.polar import PolarAxes\n",
    "from matplotlib.projections import register_projection\n",
    "from matplotlib.spines import Spine\n",
    "from matplotlib.transforms import Affine2D\n",
    "\n",
    "\n",
    "def radar_factory(num_vars, frame='circle'):\n",
    "    \"\"\"Create a radar chart with `num_vars` axes.\n",
    "\n",
    "    This function creates a RadarAxes projection and registers it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_vars : int\n",
    "        Number of variables for radar chart.\n",
    "    frame : {'circle' | 'polygon'}\n",
    "        Shape of frame surrounding axes.\n",
    "\n",
    "    \"\"\"\n",
    "    # calculate evenly-spaced axis angles\n",
    "    theta = np.linspace(0, 2*np.pi, num_vars, endpoint=False)\n",
    "    \n",
    "    class RadarTransform(PolarAxes.PolarTransform):\n",
    "        def transform_path_non_affine(self, path):\n",
    "            # Paths with non-unit interpolation steps correspond to gridlines,\n",
    "            # in which case we force interpolation (to defeat PolarTransform's\n",
    "            # autoconversion to circular arcs).\n",
    "            if path._interpolation_steps > 1:\n",
    "                path = path.interpolated(num_vars)\n",
    "            return Path(self.transform(path.vertices), path.codes)\n",
    "\n",
    "    class RadarAxes(PolarAxes):\n",
    "\n",
    "        name = 'radar'\n",
    "        \n",
    "        PolarTransform = RadarTransform\n",
    "\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            # rotate plot such that the first axis is at the top\n",
    "            self.set_theta_zero_location('N')\n",
    "\n",
    "        # def fill(self, *args, closed=True, **kwargs):\n",
    "        #     \"\"\"Override fill so that line is closed by default\"\"\"\n",
    "        #     return super().fill(closed=closed, *args, **kwargs)\n",
    "\n",
    "        def plot(self, *args, **kwargs):\n",
    "            \"\"\"Override plot so that line is closed by default\"\"\"\n",
    "            lines = super().plot(*args, **kwargs)\n",
    "            for line in lines:\n",
    "                self._close_line(line)\n",
    "\n",
    "        def _close_line(self, line):\n",
    "            x, y = line.get_data()\n",
    "            # FIXME: markers at x[0], y[0] get doubled-up\n",
    "            if x[0] != x[-1]:\n",
    "                x = np.concatenate((x, [x[0]]))\n",
    "                y = np.concatenate((y, [y[0]]))\n",
    "                line.set_data(x, y)\n",
    "\n",
    "        def set_varlabels(self, labels):\n",
    "            self.set_thetagrids(np.degrees(theta), labels)\n",
    "\n",
    "        # def set_varlabels(self, labels):\n",
    "        #     labels_with_newlines = [l.replace(' ', '\\n') for l in labels]\n",
    "        #     _lines, texts = self.set_thetagrids(np.degrees(theta), labels_with_newlines)\n",
    "        #     half = (len(texts) - 1) // 2\n",
    "        #     for t in texts[1:half]:\n",
    "        #         t.set_horizontalalignment('left')\n",
    "        #     for t in texts[-half + 1:]:\n",
    "        #         t.set_horizontalalignment('right')\n",
    "\n",
    "        def _gen_axes_patch(self):\n",
    "            # The Axes patch must be centered at (0.5, 0.5) and of radius 0.5\n",
    "            # in axes coordinates.\n",
    "            if frame == 'circle':\n",
    "                return Circle((0.5, 0.5), 0.5)\n",
    "            elif frame == 'polygon':\n",
    "                return RegularPolygon((0.5, 0.5), num_vars,\n",
    "                                      radius=.5, edgecolor=\"k\")\n",
    "            else:\n",
    "                raise ValueError(\"unknown value for 'frame': %s\" % frame)\n",
    "\n",
    "        def draw(self, renderer):\n",
    "            \"\"\" Draw. If frame is polygon, make gridlines polygon-shaped \"\"\"\n",
    "            if frame == 'polygon':\n",
    "                gridlines = self.yaxis.get_gridlines()\n",
    "                for gl in gridlines:\n",
    "                    gl.get_path()._interpolation_steps = num_vars\n",
    "            super().draw(renderer)\n",
    "\n",
    "\n",
    "        def _gen_axes_spines(self):\n",
    "            if frame == 'circle':\n",
    "                return super()._gen_axes_spines()\n",
    "            elif frame == 'polygon':\n",
    "                # spine_type must be 'left'/'right'/'top'/'bottom'/'circle'.\n",
    "                spine = Spine(axes=self,\n",
    "                              spine_type='circle',\n",
    "                              path=Path.unit_regular_polygon(num_vars))\n",
    "                # unit_regular_polygon gives a polygon of radius 1 centered at\n",
    "                # (0, 0) but we want a polygon of radius 0.5 centered at (0.5,\n",
    "                # 0.5) in axes coordinates.\n",
    "                spine.set_transform(Affine2D().scale(.5).translate(.5, .5)\n",
    "                                    + self.transAxes)\n",
    "\n",
    "\n",
    "                return {'polar': spine}\n",
    "            else:\n",
    "                raise ValueError(\"unknown value for 'frame': %s\" % frame)\n",
    "\n",
    "    register_projection(RadarAxes)\n",
    "    return theta\n",
    "\n",
    "import numpy as np \n",
    "import seaborn as sn \n",
    "import matplotlib.pyplot as plt\n",
    "for entity_type in entity_types: \n",
    "    print(entity_type)\n",
    "    radar_plot_values={}\n",
    "# for _ in range(1):\n",
    "    dfe=df[df['entity_type']==entity_type]\n",
    "    # radar_plot_values[entity_type]={}\n",
    "    for model_name in model_names:\n",
    "        df1=dfe[dfe['model']==model_name]\n",
    "        accuracies_languages_countries=[]\n",
    "        heat_map_countries=[]\n",
    "        heat_map_languages=[]\n",
    "        for country in countries:\n",
    "            heat_map_countries.append(country)\n",
    "            # print(\"For country\",country)\n",
    "            df11=df1[df1['country']==country]\n",
    "            accuracies_language=[]\n",
    "            for lang in languages:\n",
    "                df111=df11[df11['languages']==lang]\n",
    "                # print('Average Accuracy ',lang,sum(df111['score'])/len(df111)*100)\n",
    "                acc=sum(df111['score'])/len(df111)\n",
    "                accuracies_language.append(acc)\n",
    "            accuracies_languages_countries.append(accuracies_language)\n",
    "        data=np.array(accuracies_languages_countries)\n",
    "\n",
    "        for i in range(data.shape[-1]):\n",
    "            if model_name in radar_plot_values:\n",
    "                radar_plot_values[model_name].append(data[:,i])\n",
    "            else:\n",
    "                radar_plot_values[model_name]=[data[:,i]]\n",
    "\n",
    "    N = len(countries)\n",
    "    theta = radar_factory(N, frame='polygon')\n",
    "    spoke_labels=['China', 'Germany ', 'India  ', 'Japan ', 'Mexico', 'Russia', '  Spain', 'UK', 'US']\n",
    "    \n",
    "    # fig,axs=plt.subplots(figsize=(15, 13), nrows=2, ncols=4,subplot_kw=dict(projection='radar'))\n",
    "    # fig.subplots_adjust(wspace=0.7, hspace=0.5, top=0.3, bottom=0)\n",
    "\n",
    "    fig,axs=plt.subplots(figsize=(10, 15), nrows=4, ncols=2,subplot_kw=dict(projection='radar'))\n",
    "    fig.subplots_adjust(wspace=0.1, hspace=0.3, top=1, bottom=0)\n",
    "    colors = ['b', 'r', 'g', 'm', 'y','c','k']\n",
    "    for ax,(title,case_data) in zip(axs.flat,radar_plot_values.items()):\n",
    "        title_name=model_names_dic[title]\n",
    "        ax.set_rgrids([0.2, 0.4, 0.6, 0.8])\n",
    "        ax.set_title(title_name, weight='bold', size='medium', position=(0.5, 1.1),\n",
    "                        horizontalalignment='center', verticalalignment='center')\n",
    "        for d, color in zip(case_data, colors):\n",
    "            ax.plot(theta, d, color=color)\n",
    "            # ax.fill(theta, d, facecolor=color, alpha=0.25, label='_nolegend_')\n",
    "        ax.set_varlabels(spoke_labels)\n",
    "    labels = languages_iso\n",
    "    # legend = axs[0, 0].legend(labels, loc=(0.92,-0.16),ncon=6,\n",
    "    #         labelspacing=0.1, fontsize='small')\n",
    "    fig.legend(labels=labels,bbox_to_anchor=(0.93,-0.03),\n",
    "                ncol=7)\n",
    "    plt.savefig(f'plots/radial_plots/{entity_type}_country.pdf', bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spoke_labels=['China', 'Germany ', 'India  ', 'Japan ', 'Mexico', 'Russia', '  Spain', 'UK', 'US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import seaborn as sn \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "entity_types=['monuments','national_park']\n",
    "\n",
    "for entity_type in entity_types: \n",
    "    print(entity_type)\n",
    "    radar_plot_values={}\n",
    "# for _ in range(1):\n",
    "    dfe=df[df['entity_type']==entity_type]\n",
    "    for model_name in model_names:\n",
    "        df1=dfe[dfe['model']==model_name]\n",
    "        accuracies_languages_countries=[]\n",
    "        heat_map_countries=[]\n",
    "        heat_map_languages=[]\n",
    "        for country in countries:\n",
    "            heat_map_countries.append(country)\n",
    "            df11=df1[df1['country']==country]\n",
    "            accuracies_language=[]\n",
    "            for lang in languages:\n",
    "                df111=df11[df11['languages']==lang]\n",
    "                acc=int(sum(df111['score'])/len(df111)*100)\n",
    "                accuracies_language.append(acc)\n",
    "            accuracies_languages_countries.append(accuracies_language)\n",
    "        data=np.array(accuracies_languages_countries)\n",
    "\n",
    "        hm=sn.heatmap(\n",
    "        data=data,\n",
    "        xticklabels=languages_iso,\n",
    "        cmap=\"YlGnBu\",\n",
    "        # mask=mask,\n",
    "        annot=True,\n",
    "         fmt='g',\n",
    "        yticklabels=spoke_labels)\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.gca().collections[0].set_clim(0,100)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import seaborn as sn \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "plot_info={}\n",
    "countries_list=['us','china','india','uk','japan','germany', 'russia','mexico', 'spain']\n",
    "for _ in range(1): \n",
    "    dfe=df.copy()\n",
    "    for model_name in model_names:\n",
    "        df1=dfe[dfe['model']==model_name]\n",
    "        accuracies_languages_countries=[]\n",
    "        heat_map_countries=[]\n",
    "        heat_map_languages=[]\n",
    "        \n",
    "        for country in countries_list:\n",
    "            heat_map_countries.append(country)\n",
    "            df11=df1[df1['country']==country]\n",
    "            accuracies_language=[]\n",
    "            for lang in languages:\n",
    "                df111=df11[df11['languages']==lang]\n",
    "                accuracies_language.append(int(sum(df111['score'])/len(df111)*100))\n",
    "            accuracies_languages_countries.append(accuracies_language)\n",
    "        data=np.array(accuracies_languages_countries)\n",
    "        data=np.mean(data,axis=1,keepdims=True)\n",
    "\n",
    "        plot_info[model_name]=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_list=['US','China','India','Uk','Japan','Germany', 'Russia','Mexico', 'Spain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names_dic={\n",
    "     'bloomz-7b1':'Bloomz-7b1',\n",
    "     'Llama-2-7-b-chat-hf':'Llama-2-7-b-chat',\n",
    "     'Mistral-7B-Instruct':'Mistral-7B-Instruct',\n",
    "     'Meta-Llama-3-8b-Instruct':'Meta-Llama-3-8b-Instruct',\n",
    "     'Llama-2-13-b-chat-hf':'Llama-2-13-b-chat-hf',\n",
    "     'Aya':'Aya',\n",
    "     'gpt-4':'GPT-4',\n",
    "     'Mixtral-8x7B':'Mixtral-8x7B'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,5) \n",
    "plt.rcParams.update({'font.size': 20})\n",
    "N=len(plot_info)\n",
    "ind=np.arange(9)-3\n",
    "width=0.1\n",
    "for i,(model_name,acc) in enumerate(plot_info.items()):\n",
    "    acc_list=list(acc.flatten())\n",
    "    plt.bar(ind+width*i,acc_list,width,label=model_names_dic[model_name])\n",
    "plt.xticks(ind+0.35,countries_list) \n",
    "plt.xlabel(\"Countries\") \n",
    "plt.ylabel(\"Accuracy\") \n",
    "plt.savefig(f'plots/country_performance.pdf', bbox_inches=\"tight\")\n",
    "plt.legend(ncol=4,loc=(0,-0.42)) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
